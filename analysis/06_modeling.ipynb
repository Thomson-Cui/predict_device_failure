{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.io as pio\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_curve, roc_auc_score, auc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the color palette (17 colors).\n",
    "Viridis= ['#440154', '#48186a', '#472d7b', '#424086', '#3b528b', '#33638d', '#2c728e', '#26828e', '#21918c', '#1fa088',\n",
    "          '#28ae80', '#3fbc73', '#5ec962', '#84d44b', '#addc30','#d8e219', '#fde725']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93701, 39)\n"
     ]
    }
   ],
   "source": [
    "# read clean datafile\n",
    "df = pd.read_csv('../data/dataset5.gz', compression='gzip', header=0, sep=',', quotechar='\"')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this many predictors, overfitting is definitely a risk. We'll use 3 steps to avoid overfit:\n",
    "* standardize the predictors\n",
    "* regularization\n",
    "* kfold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['device', 'failure', 'ndays', 'attribute2', 'attribute3', 'attribute4',\n",
       "       'att5', 'att6', 'attribute7', 'S1F0', 'S1F1', 'W1F0', 'W1F1', 'Z1F0',\n",
       "       'Z1F1', 'attribute2_lag01', 'attribute2_lag02', 'attribute2_lag03',\n",
       "       'attribute2_lag04', 'attribute3_lag01', 'attribute3_lag02',\n",
       "       'attribute3_lag03', 'attribute3_lag04', 'attribute4_lag01',\n",
       "       'attribute4_lag02', 'attribute4_lag03', 'attribute4_lag04',\n",
       "       'att5_lag01', 'att5_lag02', 'att5_lag03', 'att5_lag04', 'att6_lag01',\n",
       "       'att6_lag02', 'att6_lag03', 'att6_lag04', 'attribute7_lag01',\n",
       "       'attribute7_lag02', 'attribute7_lag03', 'attribute7_lag04'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "df_train, df_test = train_test_split(df, test_size = .3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with imbalanced classes in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    65524\n",
       "0    65524\n",
       "Name: failure, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# Separate majority and minority classes\n",
    "df_majority = df_train[df_train['failure']==0]\n",
    "df_minority = df_train[df_train['failure']==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(df_majority),    # to match majority class\n",
    "                                 random_state=42) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_train_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_train_upsampled['failure'].value_counts()\n",
    "# hat tip: https://elitedatascience.com/imbalanced-classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final x-values (features)\n",
    "X_train=df_train_upsampled.drop(['failure', 'device'], axis=1)\n",
    "X_test=df_test.drop(['failure', 'device'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final y-values\n",
    "y_train=df_train_upsampled['failure'].values\n",
    "y1_test=df_test[['device','failure']] # Hold onto the device variable for later use, but remove it from the modeling data.\n",
    "y_test=df_test['failure'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that lengths match\n",
    "assert len(X_train)==len(y_train)\n",
    "assert len(X_test)==len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary model exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score 0.0045\n",
      "Accuracy 0.7784\n",
      "AUC Score 0.6693\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "# Fit on the training data\n",
    "gnb_model = gnb.fit(X_train, y_train)\n",
    "# Predict on the testing data\n",
    "predictions=gnb_model.predict(X_test)\n",
    "probabilities = gnb_model.predict_proba(X_test)[:,1]\n",
    "# Calculate the roc-auc score\n",
    "auc_nb=metrics.roc_auc_score(y_test, predictions)\n",
    "acc_nb = metrics.accuracy_score(y_test, predictions)\n",
    "f1_nb = metrics.f1_score(y_test, predictions)\n",
    "# Display\n",
    "print('F1 Score', \"%.4f\" % round(f1_nb,4))\n",
    "print('Accuracy', \"%.4f\" % round(acc_nb,4))\n",
    "print('AUC Score', \"%.4f\" % round(auc_nb,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score 0.0109\n",
      "Accuracy 0.8901\n",
      "AUC Score 0.7852\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "# Fit on the training data\n",
    "log_model=logreg.fit(X_train, y_train)\n",
    "# Predict on the testing data\n",
    "predictions=log_model.predict(X_test)\n",
    "probabilities = log_model.predict_proba(X_test)[:,1]\n",
    "# Calculate the roc-auc score\n",
    "auc_log=metrics.roc_auc_score(y_test, predictions)\n",
    "acc_log = metrics.accuracy_score(y_test, predictions)\n",
    "f1_log = metrics.f1_score(y_test, predictions)\n",
    "# Display\n",
    "print('F1 Score', \"%.4f\" % round(f1_log,4))\n",
    "print('Accuracy', \"%.4f\" % round(acc_log,4))\n",
    "print('AUC Score', \"%.4f\" % round(auc_log,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score 0.0202\n",
      "Accuracy 0.9965\n",
      "AUC Score 0.5187\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "# Fit on the training data\n",
    "knn_model=knn.fit(X_train, y_train)\n",
    "# Predict on the testing data\n",
    "predictions=knn_model.predict(X_test)\n",
    "probabilities = knn_model.predict_proba(X_test)[:,1]\n",
    "# Calculate the roc-auc score\n",
    "auc_knn=metrics.roc_auc_score(y_test, predictions)\n",
    "acc_knn = metrics.accuracy_score(y_test, predictions)\n",
    "f1_knn = metrics.f1_score(y_test, predictions)\n",
    "# Display\n",
    "print('F1 Score', \"%.4f\" % round(f1_knn,4))\n",
    "print('Accuracy', \"%.4f\" % round(acc_knn,4))\n",
    "print('AUC Score', \"%.4f\" % round(auc_knn,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score 0.0000\n",
      "Accuracy 0.9988\n",
      "AUC Score 0.4999\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "# Fit on the training data\n",
    "rf_model=rf.fit(X_train, y_train)\n",
    "# Predict on the testing data\n",
    "predictions=rf_model.predict(X_test)\n",
    "probabilities = rf_model.predict_proba(X_test)[:,1]\n",
    "# Calculate the roc-auc score\n",
    "auc_rf=metrics.roc_auc_score(y_test, predictions)\n",
    "acc_rf = metrics.accuracy_score(y_test, predictions)\n",
    "f1_rf = metrics.f1_score(y_test, predictions)\n",
    "# Display\n",
    "print('F1 Score', \"%.4f\" % round(f1_rf,4))\n",
    "print('Accuracy', \"%.4f\" % round(acc_rf,4))\n",
    "print('AUC Score', \"%.4f\" % round(auc_rf,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Four Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=[f1_nb, f1_log, f1_knn, f1_rf]\n",
    "acc=[acc_nb, acc_log, acc_knn, acc_rf]\n",
    "auc=[auc_nb, auc_log, auc_knn, auc_rf]\n",
    "models=['naive bayes', 'logistic regression', 'k-nearest neighbors', 'random forest']\n",
    "index=['F1 score', 'Accuracy', 'AUC score']\n",
    "results=pd.DataFrame([f1, acc, auc], index=index, columns=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naive bayes</th>\n",
       "      <th>logistic regression</th>\n",
       "      <th>k-nearest neighbors</th>\n",
       "      <th>random forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1 score</th>\n",
       "      <td>0.004476</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.778450</td>\n",
       "      <td>0.890114</td>\n",
       "      <td>0.996549</td>\n",
       "      <td>0.998826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC score</th>\n",
       "      <td>0.669322</td>\n",
       "      <td>0.785151</td>\n",
       "      <td>0.518700</td>\n",
       "      <td>0.499858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           naive bayes  logistic regression  k-nearest neighbors  \\\n",
       "F1 score      0.004476             0.010887             0.020202   \n",
       "Accuracy      0.778450             0.890114             0.996549   \n",
       "AUC score     0.669322             0.785151             0.518700   \n",
       "\n",
       "           random forest  \n",
       "F1 score        0.000000  \n",
       "Accuracy        0.998826  \n",
       "AUC score       0.499858  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle those results for comparison with tensorflow.\n",
    "with open('model_metrics.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": "#fde725"
         },
         "name": "F1 score",
         "type": "bar",
         "uid": "3e4db32d-ee20-4b7d-9ec2-4126a1db8c7d",
         "x": [
          "naive bayes",
          "logistic regression",
          "k-nearest neighbors",
          "random forest"
         ],
         "y": [
          0.004475703324808184,
          0.010886967659301952,
          0.0202020202020202,
          0
         ]
        },
        {
         "marker": {
          "color": "#28ae80"
         },
         "name": "Accuracy",
         "type": "bar",
         "uid": "44ed979d-213a-4751-85eb-0f6e9965a438",
         "x": [
          "naive bayes",
          "logistic regression",
          "k-nearest neighbors",
          "random forest"
         ],
         "y": [
          0.7784497171925581,
          0.8901141901746648,
          0.9965493934758636,
          0.9988260823165309
         ]
        },
        {
         "marker": {
          "color": "#440154"
         },
         "name": "AUC score",
         "type": "bar",
         "uid": "b7eb0748-e12e-4a56-89d1-03ccfe6e06d5",
         "x": [
          "naive bayes",
          "logistic regression",
          "k-nearest neighbors",
          "random forest"
         ],
         "y": [
          0.6693220821761732,
          0.7851506088442641,
          0.5187004201381471,
          0.49985758028911204
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Comparison of Possible Models"
        },
        "xaxis": {
         "title": {
          "text": "Predictive models"
         }
        },
        "yaxis": {
         "title": {
          "text": "Score"
         }
        }
       }
      },
      "text/html": [
       "<div id=\"3d05e32d-337e-4872-b2dc-4ab87d729ff5\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"3d05e32d-337e-4872-b2dc-4ab87d729ff5\")) {\n",
       "    Plotly.newPlot(\"3d05e32d-337e-4872-b2dc-4ab87d729ff5\", [{\"marker\": {\"color\": \"#fde725\"}, \"name\": \"F1 score\", \"x\": [\"naive bayes\", \"logistic regression\", \"k-nearest neighbors\", \"random forest\"], \"y\": [0.004475703324808184, 0.010886967659301952, 0.0202020202020202, 0.0], \"type\": \"bar\", \"uid\": \"3e4db32d-ee20-4b7d-9ec2-4126a1db8c7d\"}, {\"marker\": {\"color\": \"#28ae80\"}, \"name\": \"Accuracy\", \"x\": [\"naive bayes\", \"logistic regression\", \"k-nearest neighbors\", \"random forest\"], \"y\": [0.7784497171925581, 0.8901141901746648, 0.9965493934758636, 0.9988260823165309], \"type\": \"bar\", \"uid\": \"44ed979d-213a-4751-85eb-0f6e9965a438\"}, {\"marker\": {\"color\": \"#440154\"}, \"name\": \"AUC score\", \"x\": [\"naive bayes\", \"logistic regression\", \"k-nearest neighbors\", \"random forest\"], \"y\": [0.6693220821761732, 0.7851506088442641, 0.5187004201381471, 0.49985758028911204], \"type\": \"bar\", \"uid\": \"b7eb0748-e12e-4a56-89d1-03ccfe6e06d5\"}], {\"title\": {\"text\": \"Comparison of Possible Models\"}, \"xaxis\": {\"title\": {\"text\": \"Predictive models\"}}, \"yaxis\": {\"title\": {\"text\": \"Score\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"3d05e32d-337e-4872-b2dc-4ab87d729ff5\")) {window._Plotly.Plots.resize(document.getElementById(\"3d05e32d-337e-4872-b2dc-4ab87d729ff5\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"3d05e32d-337e-4872-b2dc-4ab87d729ff5\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"3d05e32d-337e-4872-b2dc-4ab87d729ff5\")) {\n",
       "    Plotly.newPlot(\"3d05e32d-337e-4872-b2dc-4ab87d729ff5\", [{\"marker\": {\"color\": \"#fde725\"}, \"name\": \"F1 score\", \"x\": [\"naive bayes\", \"logistic regression\", \"k-nearest neighbors\", \"random forest\"], \"y\": [0.004475703324808184, 0.010886967659301952, 0.0202020202020202, 0.0], \"type\": \"bar\", \"uid\": \"3e4db32d-ee20-4b7d-9ec2-4126a1db8c7d\"}, {\"marker\": {\"color\": \"#28ae80\"}, \"name\": \"Accuracy\", \"x\": [\"naive bayes\", \"logistic regression\", \"k-nearest neighbors\", \"random forest\"], \"y\": [0.7784497171925581, 0.8901141901746648, 0.9965493934758636, 0.9988260823165309], \"type\": \"bar\", \"uid\": \"44ed979d-213a-4751-85eb-0f6e9965a438\"}, {\"marker\": {\"color\": \"#440154\"}, \"name\": \"AUC score\", \"x\": [\"naive bayes\", \"logistic regression\", \"k-nearest neighbors\", \"random forest\"], \"y\": [0.6693220821761732, 0.7851506088442641, 0.5187004201381471, 0.49985758028911204], \"type\": \"bar\", \"uid\": \"b7eb0748-e12e-4a56-89d1-03ccfe6e06d5\"}], {\"title\": {\"text\": \"Comparison of Possible Models\"}, \"xaxis\": {\"title\": {\"text\": \"Predictive models\"}}, \"yaxis\": {\"title\": {\"text\": \"Score\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"3d05e32d-337e-4872-b2dc-4ab87d729ff5\")) {window._Plotly.Plots.resize(document.getElementById(\"3d05e32d-337e-4872-b2dc-4ab87d729ff5\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's display that with plotly.\n",
    "mydata1 = go.Bar(\n",
    "    x=results.loc['F1 score'].index,\n",
    "    y=results.loc['F1 score'],\n",
    "    name=results.index[0],\n",
    "    marker=dict(color=Viridis[16])\n",
    ")\n",
    "mydata2 = go.Bar(\n",
    "    x=results.loc['Accuracy'].index,\n",
    "    y=results.loc['Accuracy'],\n",
    "    name=results.index[1],\n",
    "    marker=dict(color=Viridis[10])\n",
    ")\n",
    "mydata3 = go.Bar(\n",
    "    x=results.loc['AUC score'].index,\n",
    "    y=results.loc['AUC score'],\n",
    "    name=results.index[2],\n",
    "    marker=dict(color=Viridis[0])\n",
    ")\n",
    "mylayout = go.Layout(\n",
    "    title='Comparison of Possible Models',\n",
    "    xaxis = dict(title = 'Predictive models'), # x-axis label\n",
    "    yaxis = dict(title = 'Score'), # y-axis label\n",
    "    \n",
    ")\n",
    "fig = go.Figure(data=[mydata1, mydata2, mydata3], layout=mylayout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looks like we're overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try optimizing the  model to avoid overfit:\n",
    "* gridsearch \n",
    "* kfold crossvalidation\n",
    "* test on hold-out dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\", color_codes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create regularization penalty space (l1=ridge, l2=lasso)\n",
    "# penalty = ['l1', 'l2'] \n",
    "\n",
    "# # Create regularization hyperparameter space\n",
    "# C = np.logspace(0, 4, 10)\n",
    "\n",
    "# # Create hyperparameter options\n",
    "# hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# # Create grid search using 5-fold cross validation\n",
    "# grid_lr = GridSearchCV(LogisticRegression(), hyperparameters, cv=5,  n_jobs = 1, verbose=0)\n",
    "# grid_lr.fit(X_train, y_train)\n",
    "# print(grid_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model using those parameters\n",
    "# log_model = grid_lr.best_estimator_\n",
    "\n",
    "# # Pickle the results of gridsearch so we don't have to do that again!\n",
    "# with open('logistic_best_params.pkl', 'wb') as f:\n",
    "#     pickle.dump(log_model, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1291.5496650148827, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Unpickle the results of gridsearch\n",
    "pickle_off = open('logistic_best_params.pkl','rb')\n",
    "log_model = pickle.load(pickle_off)\n",
    "print(log_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the testing data\n",
    "predictions=log_model.predict(X_test)\n",
    "probabilities = log_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1 score': 0.010893944248638257,\n",
       " 'accuracy score': 0.89018533670093558,\n",
       " 'error rate': 0.10981466329906442,\n",
       " 'precision score': 0.0054909560723514208,\n",
       " 'recall score': 0.68000000000000005,\n",
       " 'ROC-AUC score': 0.78518621377198616}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full list of metrics\n",
    "def model_metrics(y_test, predictions):\n",
    "    '''\n",
    "    Calculate 5 standard model metrics\n",
    "    Return a dictionary with the metrics\n",
    "    '''\n",
    "    f1 = metrics.f1_score(y_test, predictions)\n",
    "    accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "    error = 1 - accuracy\n",
    "    precision = metrics.precision_score(y_test, predictions)\n",
    "    recall = metrics.recall_score(y_test, predictions)\n",
    "    rocauc =  metrics.roc_auc_score(y_test, predictions)\n",
    "    return {'f1 score':f1, 'accuracy score': accuracy, 'error rate': error, 'precision score': precision, 'recall score': recall, 'ROC-AUC score': rocauc}\n",
    "\n",
    "model_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-AUC (Receiver Operating Characteristic - Area Under the Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b751f204556b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFPR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTPR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mroc_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mroc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roc_curve' is not defined"
     ]
    }
   ],
   "source": [
    "FPR, TPR, _ = roc_curve(y_test, predictions)\n",
    "roc_score=round(100*roc_auc_score(y_test, predictions),1)\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "mode": "lines",
         "name": "AUC: 78.5",
         "type": "scatter",
         "uid": "42e7ced3-70e1-4cc4-af15-4904d9293406",
         "x": [
          0,
          0.0013885921811578722,
          0.0013885921811578722,
          0.004521825820693584,
          0.004521825820693584,
          0.010147404400769066,
          0.010147404400769066,
          0.016947945595670443,
          0.016947945595670443,
          0.0174108096560564,
          0.0174108096560564,
          0.017873673716442356,
          0.017873673716442356,
          0.018728191981770278,
          0.018728191981770278,
          0.018763796909492272,
          0.018763796909492272,
          0.019262265897600227,
          0.019262265897600227,
          0.019297870825322225,
          0.019297870825322225,
          0.01933347575304422,
          0.01933347575304422,
          0.019653920102542192,
          0.019653920102542192,
          0.022965178380687887,
          0.022965178380687887,
          0.029658904792423273,
          0.029730114647867265,
          0.02990813928647725,
          0.02997934914192124,
          0.030691447696361177,
          0.03076265755180517,
          0.03400270597450687,
          0.03407391582995087,
          0.035462508011108736,
          0.03553371786655273,
          0.03603218685466068,
          0.03610339671010468,
          0.03895179092786442,
          0.03902300078330841,
          0.0391298155664744,
          0.039201025421918397,
          0.04108808659118422,
          0.04115929644662821,
          0.043010752688172046,
          0.043081962543616036,
          0.045396282845545824,
          0.04546749270098982,
          0.05013173823257139,
          0.050202948088015384,
          0.051164281136509296,
          0.051235490991953285,
          0.05137791070284127,
          0.051449120558285266,
          0.053015737378053124,
          0.05308694723349711,
          0.057110304066082744,
          0.05718151392152674,
          0.05789361247596667,
          0.05796482233141067,
          0.07971943316955067,
          0.07971943316955067,
          0.08395641956846828,
          0.08395641956846828,
          0.10838139998575803,
          0.10838139998575803,
          0.11026846115502385,
          0.11026846115502385,
          0.11069572028768782,
          0.11076693014313181,
          0.1118706829025137,
          0.1119418927579577,
          0.1120131026134017,
          0.11208431246884569,
          0.11350850957772556,
          0.11357971943316955,
          0.11361532436089154,
          0.11368653421633554,
          0.11400697856583351,
          0.11407818842127751,
          0.11439863277077547,
          0.11446984262621947,
          0.11450544755394147,
          0.11457665740938545,
          0.11461226233710746,
          0.11468347219255146,
          0.11475468204799544,
          0.11482589190343943,
          0.11507512639749341,
          0.11514633625293741,
          0.11649932350637328,
          0.11657053336181727,
          0.11746065655486719,
          0.11753186641031119,
          0.11895606351919105,
          0.11909848323007904,
          0.11977497685679699,
          0.11984618671224097,
          0.11995300149540697,
          0.12002421135085095,
          0.12162643309834081,
          0.12169764295378481,
          0.12194687744783878,
          0.12201808730328277,
          0.12337107455671865,
          0.12344228441216264,
          0.12347788933988464,
          0.12354909919532864,
          0.12486648152104252,
          0.12493769137648651,
          0.1250801110873745,
          0.12515132094281847,
          0.12529374065370646,
          0.12536495050915047,
          0.12568539485864844,
          0.12582781456953643,
          0.12636188848536636,
          0.12643309834081037,
          0.12664672790714235,
          0.12671793776258633,
          0.12782169052196823,
          0.12789290037741224,
          0.12810652994374422,
          0.1281777397991882,
          0.12892544328135014,
          0.12899665313679412,
          0.12949512212490208,
          0.1295663319803461,
          0.12967314676351208,
          0.12974435661895606,
          0.13013601082389803,
          0.130207220679342,
          0.130314035462508,
          0.130314035462508,
          0.130420850245674,
          0.130492060101118,
          0.13074129459517198,
          0.13081250445061596,
          0.1325571459089938,
          0.1326995656198818,
          0.1327707754753258,
          0.1327707754753258,
          0.13330484939115575,
          0.13337605924659973,
          0.1336252937406537,
          0.1336965035960977,
          0.13462223171686963,
          0.1346934415723136,
          0.13487146621092358,
          0.1349782809940896,
          0.13512070070497756,
          0.13526312041586555,
          0.13551235490991953,
          0.13565477462080752,
          0.1357259844762515,
          0.13579719433169551,
          0.13647368795841344,
          0.13654489781385742,
          0.13665171259702344,
          0.13672292245246742,
          0.13739941607918535,
          0.13747062593462936,
          0.13782667521184933,
          0.1378978850672933,
          0.1380046998504593,
          0.1380759097059033,
          0.13839635405540127,
          0.13846756391084525,
          0.13850316883856725,
          0.13857437869401126,
          0.13882361318806521,
          0.13889482304350922,
          0.13950010681478317,
          0.13957131667022715,
          0.14078188421277504,
          0.14085309406821905,
          0.14195684682760093,
          0.14202805668304494,
          0.1422060813216549,
          0.14227729117709892,
          0.1424197108879869,
          0.1424909207434309,
          0.14323862422559283,
          0.1433098340810368,
          0.14377269814142277,
          0.14384390799686678,
          0.1445916114790287,
          0.1446628213344727,
          0.14494766075624865,
          0.14501887061169266,
          0.14509008046713665,
          0.14516129032258066,
          0.14583778394929858,
          0.14594459873246457,
          0.14601580858790858,
          0.14633625293740654,
          0.14640746279285052,
          0.1466923022146265,
          0.1467635120700705,
          0.14701274656412447,
          0.14708395641956848,
          0.14729758598590045,
          0.14740440076906644,
          0.14754682047995443,
          0.1478672648294524,
          0.14793847468489638,
          0.14825891903439437,
          0.14833012888983835,
          0.14872178309478032,
          0.1487929929502243,
          0.14904222744427828,
          0.14918464715516627,
          0.14922025208288828,
          0.14929146193833226,
          0.14943388164922025,
          0.14950509150466423,
          0.14957630136010824,
          0.14968311614327423,
          0.1498967457096062,
          0.14996795556505021,
          0.1500747703482162,
          0.15014598020366018,
          0.15025279498682617,
          0.15032400484227018,
          0.15050202948088015,
          0.15064444919176814,
          0.15071565904721212,
          0.15092928861354413,
          0.1510004984689881,
          0.15146336252937406,
          0.15157017731254005,
          0.15164138716798406,
          0.15171259702342804,
          0.15178380687887202,
          0.15189062166203804,
          0.15196183151748202,
          0.15249590543331196,
          0.15263832514419995,
          0.15270953499964396,
          0.15292316456597593,
          0.15302997934914192,
          0.1533148187709179,
          0.1533860286263619,
          0.15349284340952787,
          0.15356405326497188,
          0.15359965819269386,
          0.15367086804813787,
          0.15384889268674784,
          0.15392010254219185,
          0.15406252225307981,
          0.15416933703624583,
          0.15441857153029978,
          0.1544897813857438,
          0.15463220109663178,
          0.15470341095207576,
          0.15484583066296376,
          0.15491704051840774,
          0.15513067008473974,
          0.15520187994018372,
          0.1553086947233497,
          0.1553799045787937,
          0.1555935341451257,
          0.15570034892829168,
          0.15577155878373566,
          0.15584276863917967,
          0.15591397849462366,
          0.15602079327778964,
          0.15612760806095563,
          0.15619881791639964,
          0.15644805241045362,
          0.1565192622658976,
          0.15669728690450757,
          0.15676849675995158,
          0.15683970661539556,
          0.15691091647083957,
          0.15694652139856155,
          0.15701773125400556,
          0.15737378053122553,
          0.1574449903866695,
          0.1575874100975575,
          0.15765861995300148,
          0.1577298298084455,
          0.15780103966388948,
          0.15783664459161148,
          0.15794345937477747,
          0.15805027415794345,
          0.15812148401338746,
          0.15826390372427543,
          0.15833511357971944,
          0.15840632343516342,
          0.15847753329060743,
          0.1586199530014954,
          0.1586911628569394,
          0.15897600227871536,
          0.15904721213415937,
          0.15918963184504736,
          0.15926084170049135,
          0.15933205155593533,
          0.15965249590543332,
          0.1597237057608773,
          0.15993733532720927,
          0.16000854518265328,
          0.1607918535925372,
          0.1608630634479812,
          0.1609342733034252,
          0.1609342733034252,
          0.16132592750836716,
          0.16139713736381114,
          0.16161076693014312,
          0.16171758171330913,
          0.1617531866410311,
          0.16182439649647512,
          0.1618600014241971,
          0.1619312112796411,
          0.16214484084597308,
          0.16221605070141706,
          0.16225165562913907,
          0.16232286548458308,
          0.163034964039023,
          0.163106173894467,
          0.16349782809940896,
          0.16356903795485295,
          0.16374706259346294,
          0.16381827244890693,
          0.16385387737662893,
          0.1639250872320729,
          0.16428113650929288,
          0.1643523463647369,
          0.16445916114790288,
          0.16453037100334686,
          0.16467279071423485,
          0.16474400056967883,
          0.16485081535284482,
          0.16495763013601084,
          0.16545609912411877,
          0.16552730897956278,
          0.16559851883500676,
          0.16574093854589475,
          0.16577654347361676,
          0.16588335825678274,
          0.1661681976785587,
          0.1662394075340027,
          0.16670227159438866,
          0.16677348144983264,
          0.16709392579933063,
          0.16716513565477462,
          0.16720074058249662,
          0.1673075553656626,
          0.1675567898597166,
          0.16762799971516057,
          0.16777041942604856,
          0.16784162928149257,
          0.16794844406465856,
          0.16801965392010254,
          0.16812646870326853,
          0.1683400982696005,
          0.1684113081250445,
          0.1685181229082105,
          0.16858933276365448,
          0.16883856725770846,
          0.16890977711315247,
          0.16901659189631846,
          0.16908780175176244,
          0.16912340667948444,
          0.16919461653492843,
          0.1697286904507584,
          0.16979990030620237,
          0.16983550523392438,
          0.16994232001709036,
          0.16997792494481237,
          0.17004913480025635,
          0.17047639393292033,
          0.17058320871608632,
          0.1706544185715303,
          0.17076123335469628,
          0.17101046784875026,
          0.17115288755963826,
          0.17129530727052625,
          0.17136651712597023,
          0.17232785017446414,
          0.17239906002990815,
          0.17243466495763013,
          0.17250587481307414,
          0.17336039307840206,
          0.17343160293384605,
          0.17385886206651,
          0.17396567684967598,
          0.17435733105461795,
          0.17442854091006196,
          0.17489140497044792,
          0.1749626148258919,
          0.17531866410311187,
          0.17538987395855588,
          0.17571031830805384,
          0.17578152816349782,
          0.1758883429466638,
          0.17677846613971374,
          0.17684967599515772,
          0.17692088585060173,
          0.17702770063376772,
          0.17738374991098768,
          0.17752616962187567,
          0.17756177454959765,
          0.17763298440504166,
          0.17880794701986755,
          0.17887915687531156,
          0.17948444064658547,
          0.17955565050202948,
          0.17994730470697146,
          0.18008972441785942,
          0.1805525884782454,
          0.18062379833368938,
          0.18073061311685537,
          0.18080182297229935,
          0.18097984761090935,
          0.18105105746635333,
          0.1813002919604073,
          0.18137150181585132,
          0.18190557573168126,
          0.18197678558712527,
          0.1823684397920672,
          0.18243964964751122,
          0.1825108595029552,
          0.1826532792138432,
          0.18297372356334116,
          0.18304493341878517,
          0.18311614327422915,
          0.18318735312967316,
          0.18393505661183507,
          0.18404187139500106,
          0.18461155023855302,
          0.184682760093997,
          0.18511001922666098,
          0.18518122908210496,
          0.18571530299793493,
          0.1857865128533789,
          0.1858933276365449,
          0.18596453749198888,
          0.18642740155237486,
          0.18649861140781884,
          0.18867051199886065,
          0.18874172185430463,
          0.18891974649291463,
          0.1889909563483586,
          0.1900947091077405,
          0.1901659189631845,
          0.1902015238909065,
          0.1902727337463505,
          0.19212418998789432,
          0.1922310047710603,
          0.19287189347005626,
          0.19294310332550024,
          0.1934771772413302,
          0.1935483870967742,
          0.19750053407391582,
          0.1976073488570818,
          0.1988179163996297,
          0.1988891262550737,
          0.20195115003916542,
          0.20202235989460943,
          0.5359253720714947,
          0.5359253720714947,
          0.8402762942391226,
          0.8402762942391226,
          0.8840703553371787,
          0.8840703553371787,
          0.9212775048066653,
          0.9213487146621092,
          0.9214555294452752,
          0.9215267393007193,
          0.9218827885779391,
          0.9219539984333832,
          0.923734244819483,
          0.923805454674927,
          0.923912269458093,
          0.923983479313537,
          0.924268318735313,
          0.924375133518479,
          0.9261909848323008,
          0.9262621946877447,
          0.9265114291817987,
          0.9265826390372428,
          0.9271879228085167,
          0.9272947375916827,
          0.9295378480381685,
          0.9296446628213345,
          0.9322438225450402,
          0.9323150324004842,
          0.9327066866054262,
          0.9327778964608702,
          0.9336680196539201,
          0.933739229509364,
          0.9339172541479741,
          0.9339884640034181,
          0.935127821690522,
          0.935234636473688,
          0.93580431531724,
          0.9358755251726839,
          0.9362315744499039,
          0.9363383892330699,
          0.9368012532934558,
          0.9369436730043438,
          0.9371216976429538,
          0.9372285124261198,
          0.9376557715587838,
          0.9377269814142277,
          0.9380474257637257,
          0.9381186356191696,
          0.9399700918607136,
          0.9400413017161575,
          0.9401837214270455,
          0.9402549312824895,
          0.9409314249092074,
          0.9410026347646514,
          0.9434949797051913,
          0.9435661895606352,
          0.945382040874457,
          0.945488855657623,
          0.9471266823328348,
          0.9471978921882789,
          0.9473759168268888,
          0.9474471266823329,
          0.9478387808872748,
          0.9479099907427188,
          0.9491561632129887,
          0.9492273730684326,
          0.9502955209000926,
          0.9503667307555366,
          0.9504735455387026,
          0.9505447553941465,
          0.9507227800327566,
          0.9507939898882005,
          0.9512924588763085,
          0.9513636687317525,
          0.9514704835149185,
          0.9515416933703624,
          0.9518265327921385,
          0.9518977426475824,
          0.9521469771416364,
          0.9522181869970804,
          0.9522893968525243,
          0.9523606067079684,
          0.9528234707683544,
          0.9528946806237983,
          0.9529658904792423,
          0.9530371003346864,
          0.9533931496119062,
          0.9534643594673503,
          0.9536423841059603,
          0.9537135939614042,
          0.9540340383109023,
          0.9541052481663462,
          0.9543900875881222,
          0.9544612974435662,
          0.9545681122267322,
          0.9546393220821762,
          0.9548885565762302,
          0.9549597664316741,
          0.9553870255643381,
          0.9555294452752261,
          0.9557430748415581,
          0.955814284697002,
          0.95595670440789,
          0.956027914263334,
          0.956063519191056,
          0.9561347290465,
          0.956170333974222,
          0.956277148757388,
          0.956383963540554,
          0.95649077832372,
          0.956597593106886,
          0.95666880296233,
          0.956775617745496,
          0.956882432528662,
          0.9571316670227159,
          0.9572384818058819,
          0.957309691661326,
          0.9575945310831019,
          0.9577013458662679,
          0.9580573951434879,
          0.9581998148543759,
          0.9582710247098198,
          0.9584134444207079,
          0.9585558641315958,
          0.9586982838424838,
          0.9587338887702058,
          0.9588763084810937,
          0.9591611479028698,
          0.9592323577583137,
          0.9594459873246457,
          0.9595171971800898,
          0.9596240119632558,
          0.9604429253008616,
          0.9605141351563057,
          0.9609413942889696,
          0.9610482090721356,
          0.9612618386384676,
          0.9614042583493555,
          0.9616178879156876,
          0.9616890977711315,
          0.9620095421206295,
          0.9620095421206295,
          0.9621163569037955,
          0.9621875667592394,
          0.9623299864701275,
          0.9624011963255714,
          0.9626148258919034,
          0.9627216406750694,
          0.9628996653136794,
          0.9629708751691234,
          0.9631132948800114,
          0.9632557145908994,
          0.9633269244463434,
          0.9635761589403974,
          0.9636473687958413,
          0.9637185786512853,
          0.9637897885067294,
          0.9640034180730613,
          0.9640746279285053,
          0.9643594673502813,
          0.9644306772057253,
          0.9644662821334473,
          0.9645374919888913,
          0.9645730969166133,
          0.9646443067720573,
          0.9651427757601652,
          0.9652139856156092,
          0.9656412447482732,
          0.9657124546037171,
          0.9658548743146051,
          0.9659260841700491,
          0.9663177383749911,
          0.9663889482304351,
          0.966460158085879,
          0.9665313679413231,
          0.9667449975076551,
          0.9668518122908211,
          0.966923022146265,
          0.9669942320017091,
          0.967065441857153,
          0.967136651712597,
          0.967350281278929,
          0.967421491134373,
          0.967635120700705,
          0.967706330556149,
          0.967813145339315,
          0.9680267749056469,
          0.9680979847610909,
          0.9681335896888129,
          0.9682404044719789,
          0.9684540340383109,
          0.9685608488214769,
          0.9685964537491989,
          0.9686676636046428,
          0.9687744783878088,
          0.9688100833155309,
          0.9688812931709748,
          0.9689525030264189,
          0.9690237128818628,
          0.9690593178095849,
          0.9691661325927509,
          0.9692729473759168,
          0.9693441572313608,
          0.9694153670868049,
          0.9694865769422488,
          0.9695221818699709,
          0.9696646015808588,
          0.9697714163640248,
          0.9698426262194688,
          0.9700562557858008,
          0.9701274656412447,
          0.9704123050630207,
          0.9704835149184647,
          0.9710887986897386,
          0.9711600085451827,
          0.9712668233283487,
          0.9713380331837926,
          0.9720501317382326,
          0.9721213415936766,
          0.9722637613045646,
          0.9723349711600086,
          0.9724061810154525,
          0.9726910204372285,
          0.9729758598590045,
          0.9736167485580004,
          0.9737235633411664,
          0.9739015879797764,
          0.9740084027629424,
          0.9740796126183864,
          0.9976500747703482,
          0.9977212846257922,
          0.9980061240475682,
          0.9981485437584562,
          0.9982909634693442,
          0.9983621733247882,
          0.9995015310118921,
          0.9996083457950581,
          1
         ],
         "y": [
          0.04,
          0.04,
          0.08,
          0.08,
          0.12,
          0.12,
          0.16,
          0.16,
          0.2,
          0.2,
          0.24,
          0.24,
          0.28,
          0.28,
          0.32,
          0.32,
          0.36,
          0.36,
          0.4,
          0.4,
          0.44,
          0.44,
          0.48,
          0.48,
          0.52,
          0.52,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.56,
          0.6,
          0.6,
          0.64,
          0.64,
          0.68,
          0.68,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.72,
          0.76,
          0.76,
          0.76,
          0.76,
          0.76,
          0.76,
          0.76,
          0.76,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.84,
          0.88,
          0.88,
          0.92,
          0.92,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          0.96,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ]
        },
        {
         "mode": "lines",
         "name": "Baseline Area: 50.0",
         "type": "scatter",
         "uid": "aa64faeb-39bc-4174-a9a9-3984dafbe6fa",
         "x": [
          0,
          1
         ],
         "y": [
          0,
          1
         ]
        }
       ],
       "layout": {
        "height": 600,
        "title": {
         "text": "Receiver Operating Characteristic - Area Under Curve"
        },
        "width": 650
       }
      },
      "text/html": [
       "<div id=\"54a814e3-e407-463c-a483-104d3a725f25\" style=\"height: 600px; width: 650px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"54a814e3-e407-463c-a483-104d3a725f25\")) {\n",
       "    Plotly.newPlot(\"54a814e3-e407-463c-a483-104d3a725f25\", [{\"mode\": \"lines\", \"name\": \"AUC: 78.5\", \"x\": [0.0, 0.0013885921811578722, 0.0013885921811578722, 0.004521825820693584, 0.004521825820693584, 0.010147404400769066, 0.010147404400769066, 0.016947945595670443, 0.016947945595670443, 0.0174108096560564, 0.0174108096560564, 0.017873673716442356, 0.017873673716442356, 0.018728191981770278, 0.018728191981770278, 0.018763796909492272, 0.018763796909492272, 0.019262265897600227, 0.019262265897600227, 0.019297870825322225, 0.019297870825322225, 0.01933347575304422, 0.01933347575304422, 0.019653920102542192, 0.019653920102542192, 0.022965178380687887, 0.022965178380687887, 0.029658904792423273, 0.029730114647867265, 0.02990813928647725, 0.02997934914192124, 0.030691447696361177, 0.03076265755180517, 0.03400270597450687, 0.03407391582995087, 0.035462508011108736, 0.03553371786655273, 0.03603218685466068, 0.03610339671010468, 0.03895179092786442, 0.03902300078330841, 0.0391298155664744, 0.039201025421918397, 0.04108808659118422, 0.04115929644662821, 0.043010752688172046, 0.043081962543616036, 0.045396282845545824, 0.04546749270098982, 0.05013173823257139, 0.050202948088015384, 0.051164281136509296, 0.051235490991953285, 0.05137791070284127, 0.051449120558285266, 0.053015737378053124, 0.05308694723349711, 0.057110304066082744, 0.05718151392152674, 0.05789361247596667, 0.05796482233141067, 0.07971943316955067, 0.07971943316955067, 0.08395641956846828, 0.08395641956846828, 0.10838139998575803, 0.10838139998575803, 0.11026846115502385, 0.11026846115502385, 0.11069572028768782, 0.11076693014313181, 0.1118706829025137, 0.1119418927579577, 0.1120131026134017, 0.11208431246884569, 0.11350850957772556, 0.11357971943316955, 0.11361532436089154, 0.11368653421633554, 0.11400697856583351, 0.11407818842127751, 0.11439863277077547, 0.11446984262621947, 0.11450544755394147, 0.11457665740938545, 0.11461226233710746, 0.11468347219255146, 0.11475468204799544, 0.11482589190343943, 0.11507512639749341, 0.11514633625293741, 0.11649932350637328, 0.11657053336181727, 0.11746065655486719, 0.11753186641031119, 0.11895606351919105, 0.11909848323007904, 0.11977497685679699, 0.11984618671224097, 0.11995300149540697, 0.12002421135085095, 0.12162643309834081, 0.12169764295378481, 0.12194687744783878, 0.12201808730328277, 0.12337107455671865, 0.12344228441216264, 0.12347788933988464, 0.12354909919532864, 0.12486648152104252, 0.12493769137648651, 0.1250801110873745, 0.12515132094281847, 0.12529374065370646, 0.12536495050915047, 0.12568539485864844, 0.12582781456953643, 0.12636188848536636, 0.12643309834081037, 0.12664672790714235, 0.12671793776258633, 0.12782169052196823, 0.12789290037741224, 0.12810652994374422, 0.1281777397991882, 0.12892544328135014, 0.12899665313679412, 0.12949512212490208, 0.1295663319803461, 0.12967314676351208, 0.12974435661895606, 0.13013601082389803, 0.130207220679342, 0.130314035462508, 0.130314035462508, 0.130420850245674, 0.130492060101118, 0.13074129459517198, 0.13081250445061596, 0.1325571459089938, 0.1326995656198818, 0.1327707754753258, 0.1327707754753258, 0.13330484939115575, 0.13337605924659973, 0.1336252937406537, 0.1336965035960977, 0.13462223171686963, 0.1346934415723136, 0.13487146621092358, 0.1349782809940896, 0.13512070070497756, 0.13526312041586555, 0.13551235490991953, 0.13565477462080752, 0.1357259844762515, 0.13579719433169551, 0.13647368795841344, 0.13654489781385742, 0.13665171259702344, 0.13672292245246742, 0.13739941607918535, 0.13747062593462936, 0.13782667521184933, 0.1378978850672933, 0.1380046998504593, 0.1380759097059033, 0.13839635405540127, 0.13846756391084525, 0.13850316883856725, 0.13857437869401126, 0.13882361318806521, 0.13889482304350922, 0.13950010681478317, 0.13957131667022715, 0.14078188421277504, 0.14085309406821905, 0.14195684682760093, 0.14202805668304494, 0.1422060813216549, 0.14227729117709892, 0.1424197108879869, 0.1424909207434309, 0.14323862422559283, 0.1433098340810368, 0.14377269814142277, 0.14384390799686678, 0.1445916114790287, 0.1446628213344727, 0.14494766075624865, 0.14501887061169266, 0.14509008046713665, 0.14516129032258066, 0.14583778394929858, 0.14594459873246457, 0.14601580858790858, 0.14633625293740654, 0.14640746279285052, 0.1466923022146265, 0.1467635120700705, 0.14701274656412447, 0.14708395641956848, 0.14729758598590045, 0.14740440076906644, 0.14754682047995443, 0.1478672648294524, 0.14793847468489638, 0.14825891903439437, 0.14833012888983835, 0.14872178309478032, 0.1487929929502243, 0.14904222744427828, 0.14918464715516627, 0.14922025208288828, 0.14929146193833226, 0.14943388164922025, 0.14950509150466423, 0.14957630136010824, 0.14968311614327423, 0.1498967457096062, 0.14996795556505021, 0.1500747703482162, 0.15014598020366018, 0.15025279498682617, 0.15032400484227018, 0.15050202948088015, 0.15064444919176814, 0.15071565904721212, 0.15092928861354413, 0.1510004984689881, 0.15146336252937406, 0.15157017731254005, 0.15164138716798406, 0.15171259702342804, 0.15178380687887202, 0.15189062166203804, 0.15196183151748202, 0.15249590543331196, 0.15263832514419995, 0.15270953499964396, 0.15292316456597593, 0.15302997934914192, 0.1533148187709179, 0.1533860286263619, 0.15349284340952787, 0.15356405326497188, 0.15359965819269386, 0.15367086804813787, 0.15384889268674784, 0.15392010254219185, 0.15406252225307981, 0.15416933703624583, 0.15441857153029978, 0.1544897813857438, 0.15463220109663178, 0.15470341095207576, 0.15484583066296376, 0.15491704051840774, 0.15513067008473974, 0.15520187994018372, 0.1553086947233497, 0.1553799045787937, 0.1555935341451257, 0.15570034892829168, 0.15577155878373566, 0.15584276863917967, 0.15591397849462366, 0.15602079327778964, 0.15612760806095563, 0.15619881791639964, 0.15644805241045362, 0.1565192622658976, 0.15669728690450757, 0.15676849675995158, 0.15683970661539556, 0.15691091647083957, 0.15694652139856155, 0.15701773125400556, 0.15737378053122553, 0.1574449903866695, 0.1575874100975575, 0.15765861995300148, 0.1577298298084455, 0.15780103966388948, 0.15783664459161148, 0.15794345937477747, 0.15805027415794345, 0.15812148401338746, 0.15826390372427543, 0.15833511357971944, 0.15840632343516342, 0.15847753329060743, 0.1586199530014954, 0.1586911628569394, 0.15897600227871536, 0.15904721213415937, 0.15918963184504736, 0.15926084170049135, 0.15933205155593533, 0.15965249590543332, 0.1597237057608773, 0.15993733532720927, 0.16000854518265328, 0.1607918535925372, 0.1608630634479812, 0.1609342733034252, 0.1609342733034252, 0.16132592750836716, 0.16139713736381114, 0.16161076693014312, 0.16171758171330913, 0.1617531866410311, 0.16182439649647512, 0.1618600014241971, 0.1619312112796411, 0.16214484084597308, 0.16221605070141706, 0.16225165562913907, 0.16232286548458308, 0.163034964039023, 0.163106173894467, 0.16349782809940896, 0.16356903795485295, 0.16374706259346294, 0.16381827244890693, 0.16385387737662893, 0.1639250872320729, 0.16428113650929288, 0.1643523463647369, 0.16445916114790288, 0.16453037100334686, 0.16467279071423485, 0.16474400056967883, 0.16485081535284482, 0.16495763013601084, 0.16545609912411877, 0.16552730897956278, 0.16559851883500676, 0.16574093854589475, 0.16577654347361676, 0.16588335825678274, 0.1661681976785587, 0.1662394075340027, 0.16670227159438866, 0.16677348144983264, 0.16709392579933063, 0.16716513565477462, 0.16720074058249662, 0.1673075553656626, 0.1675567898597166, 0.16762799971516057, 0.16777041942604856, 0.16784162928149257, 0.16794844406465856, 0.16801965392010254, 0.16812646870326853, 0.1683400982696005, 0.1684113081250445, 0.1685181229082105, 0.16858933276365448, 0.16883856725770846, 0.16890977711315247, 0.16901659189631846, 0.16908780175176244, 0.16912340667948444, 0.16919461653492843, 0.1697286904507584, 0.16979990030620237, 0.16983550523392438, 0.16994232001709036, 0.16997792494481237, 0.17004913480025635, 0.17047639393292033, 0.17058320871608632, 0.1706544185715303, 0.17076123335469628, 0.17101046784875026, 0.17115288755963826, 0.17129530727052625, 0.17136651712597023, 0.17232785017446414, 0.17239906002990815, 0.17243466495763013, 0.17250587481307414, 0.17336039307840206, 0.17343160293384605, 0.17385886206651, 0.17396567684967598, 0.17435733105461795, 0.17442854091006196, 0.17489140497044792, 0.1749626148258919, 0.17531866410311187, 0.17538987395855588, 0.17571031830805384, 0.17578152816349782, 0.1758883429466638, 0.17677846613971374, 0.17684967599515772, 0.17692088585060173, 0.17702770063376772, 0.17738374991098768, 0.17752616962187567, 0.17756177454959765, 0.17763298440504166, 0.17880794701986755, 0.17887915687531156, 0.17948444064658547, 0.17955565050202948, 0.17994730470697146, 0.18008972441785942, 0.1805525884782454, 0.18062379833368938, 0.18073061311685537, 0.18080182297229935, 0.18097984761090935, 0.18105105746635333, 0.1813002919604073, 0.18137150181585132, 0.18190557573168126, 0.18197678558712527, 0.1823684397920672, 0.18243964964751122, 0.1825108595029552, 0.1826532792138432, 0.18297372356334116, 0.18304493341878517, 0.18311614327422915, 0.18318735312967316, 0.18393505661183507, 0.18404187139500106, 0.18461155023855302, 0.184682760093997, 0.18511001922666098, 0.18518122908210496, 0.18571530299793493, 0.1857865128533789, 0.1858933276365449, 0.18596453749198888, 0.18642740155237486, 0.18649861140781884, 0.18867051199886065, 0.18874172185430463, 0.18891974649291463, 0.1889909563483586, 0.1900947091077405, 0.1901659189631845, 0.1902015238909065, 0.1902727337463505, 0.19212418998789432, 0.1922310047710603, 0.19287189347005626, 0.19294310332550024, 0.1934771772413302, 0.1935483870967742, 0.19750053407391582, 0.1976073488570818, 0.1988179163996297, 0.1988891262550737, 0.20195115003916542, 0.20202235989460943, 0.5359253720714947, 0.5359253720714947, 0.8402762942391226, 0.8402762942391226, 0.8840703553371787, 0.8840703553371787, 0.9212775048066653, 0.9213487146621092, 0.9214555294452752, 0.9215267393007193, 0.9218827885779391, 0.9219539984333832, 0.923734244819483, 0.923805454674927, 0.923912269458093, 0.923983479313537, 0.924268318735313, 0.924375133518479, 0.9261909848323008, 0.9262621946877447, 0.9265114291817987, 0.9265826390372428, 0.9271879228085167, 0.9272947375916827, 0.9295378480381685, 0.9296446628213345, 0.9322438225450402, 0.9323150324004842, 0.9327066866054262, 0.9327778964608702, 0.9336680196539201, 0.933739229509364, 0.9339172541479741, 0.9339884640034181, 0.935127821690522, 0.935234636473688, 0.93580431531724, 0.9358755251726839, 0.9362315744499039, 0.9363383892330699, 0.9368012532934558, 0.9369436730043438, 0.9371216976429538, 0.9372285124261198, 0.9376557715587838, 0.9377269814142277, 0.9380474257637257, 0.9381186356191696, 0.9399700918607136, 0.9400413017161575, 0.9401837214270455, 0.9402549312824895, 0.9409314249092074, 0.9410026347646514, 0.9434949797051913, 0.9435661895606352, 0.945382040874457, 0.945488855657623, 0.9471266823328348, 0.9471978921882789, 0.9473759168268888, 0.9474471266823329, 0.9478387808872748, 0.9479099907427188, 0.9491561632129887, 0.9492273730684326, 0.9502955209000926, 0.9503667307555366, 0.9504735455387026, 0.9505447553941465, 0.9507227800327566, 0.9507939898882005, 0.9512924588763085, 0.9513636687317525, 0.9514704835149185, 0.9515416933703624, 0.9518265327921385, 0.9518977426475824, 0.9521469771416364, 0.9522181869970804, 0.9522893968525243, 0.9523606067079684, 0.9528234707683544, 0.9528946806237983, 0.9529658904792423, 0.9530371003346864, 0.9533931496119062, 0.9534643594673503, 0.9536423841059603, 0.9537135939614042, 0.9540340383109023, 0.9541052481663462, 0.9543900875881222, 0.9544612974435662, 0.9545681122267322, 0.9546393220821762, 0.9548885565762302, 0.9549597664316741, 0.9553870255643381, 0.9555294452752261, 0.9557430748415581, 0.955814284697002, 0.95595670440789, 0.956027914263334, 0.956063519191056, 0.9561347290465, 0.956170333974222, 0.956277148757388, 0.956383963540554, 0.95649077832372, 0.956597593106886, 0.95666880296233, 0.956775617745496, 0.956882432528662, 0.9571316670227159, 0.9572384818058819, 0.957309691661326, 0.9575945310831019, 0.9577013458662679, 0.9580573951434879, 0.9581998148543759, 0.9582710247098198, 0.9584134444207079, 0.9585558641315958, 0.9586982838424838, 0.9587338887702058, 0.9588763084810937, 0.9591611479028698, 0.9592323577583137, 0.9594459873246457, 0.9595171971800898, 0.9596240119632558, 0.9604429253008616, 0.9605141351563057, 0.9609413942889696, 0.9610482090721356, 0.9612618386384676, 0.9614042583493555, 0.9616178879156876, 0.9616890977711315, 0.9620095421206295, 0.9620095421206295, 0.9621163569037955, 0.9621875667592394, 0.9623299864701275, 0.9624011963255714, 0.9626148258919034, 0.9627216406750694, 0.9628996653136794, 0.9629708751691234, 0.9631132948800114, 0.9632557145908994, 0.9633269244463434, 0.9635761589403974, 0.9636473687958413, 0.9637185786512853, 0.9637897885067294, 0.9640034180730613, 0.9640746279285053, 0.9643594673502813, 0.9644306772057253, 0.9644662821334473, 0.9645374919888913, 0.9645730969166133, 0.9646443067720573, 0.9651427757601652, 0.9652139856156092, 0.9656412447482732, 0.9657124546037171, 0.9658548743146051, 0.9659260841700491, 0.9663177383749911, 0.9663889482304351, 0.966460158085879, 0.9665313679413231, 0.9667449975076551, 0.9668518122908211, 0.966923022146265, 0.9669942320017091, 0.967065441857153, 0.967136651712597, 0.967350281278929, 0.967421491134373, 0.967635120700705, 0.967706330556149, 0.967813145339315, 0.9680267749056469, 0.9680979847610909, 0.9681335896888129, 0.9682404044719789, 0.9684540340383109, 0.9685608488214769, 0.9685964537491989, 0.9686676636046428, 0.9687744783878088, 0.9688100833155309, 0.9688812931709748, 0.9689525030264189, 0.9690237128818628, 0.9690593178095849, 0.9691661325927509, 0.9692729473759168, 0.9693441572313608, 0.9694153670868049, 0.9694865769422488, 0.9695221818699709, 0.9696646015808588, 0.9697714163640248, 0.9698426262194688, 0.9700562557858008, 0.9701274656412447, 0.9704123050630207, 0.9704835149184647, 0.9710887986897386, 0.9711600085451827, 0.9712668233283487, 0.9713380331837926, 0.9720501317382326, 0.9721213415936766, 0.9722637613045646, 0.9723349711600086, 0.9724061810154525, 0.9726910204372285, 0.9729758598590045, 0.9736167485580004, 0.9737235633411664, 0.9739015879797764, 0.9740084027629424, 0.9740796126183864, 0.9976500747703482, 0.9977212846257922, 0.9980061240475682, 0.9981485437584562, 0.9982909634693442, 0.9983621733247882, 0.9995015310118921, 0.9996083457950581, 1.0], \"y\": [0.04, 0.04, 0.08, 0.08, 0.12, 0.12, 0.16, 0.16, 0.2, 0.2, 0.24, 0.24, 0.28, 0.28, 0.32, 0.32, 0.36, 0.36, 0.4, 0.4, 0.44, 0.44, 0.48, 0.48, 0.52, 0.52, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.6, 0.6, 0.64, 0.64, 0.68, 0.68, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.88, 0.88, 0.92, 0.92, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \"type\": \"scatter\", \"uid\": \"42e7ced3-70e1-4cc4-af15-4904d9293406\"}, {\"mode\": \"lines\", \"name\": \"Baseline Area: 50.0\", \"x\": [0, 1], \"y\": [0, 1], \"type\": \"scatter\", \"uid\": \"aa64faeb-39bc-4174-a9a9-3984dafbe6fa\"}], {\"height\": 600, \"title\": {\"text\": \"Receiver Operating Characteristic - Area Under Curve\"}, \"width\": 650}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"54a814e3-e407-463c-a483-104d3a725f25\" style=\"height: 600px; width: 650px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"54a814e3-e407-463c-a483-104d3a725f25\")) {\n",
       "    Plotly.newPlot(\"54a814e3-e407-463c-a483-104d3a725f25\", [{\"mode\": \"lines\", \"name\": \"AUC: 78.5\", \"x\": [0.0, 0.0013885921811578722, 0.0013885921811578722, 0.004521825820693584, 0.004521825820693584, 0.010147404400769066, 0.010147404400769066, 0.016947945595670443, 0.016947945595670443, 0.0174108096560564, 0.0174108096560564, 0.017873673716442356, 0.017873673716442356, 0.018728191981770278, 0.018728191981770278, 0.018763796909492272, 0.018763796909492272, 0.019262265897600227, 0.019262265897600227, 0.019297870825322225, 0.019297870825322225, 0.01933347575304422, 0.01933347575304422, 0.019653920102542192, 0.019653920102542192, 0.022965178380687887, 0.022965178380687887, 0.029658904792423273, 0.029730114647867265, 0.02990813928647725, 0.02997934914192124, 0.030691447696361177, 0.03076265755180517, 0.03400270597450687, 0.03407391582995087, 0.035462508011108736, 0.03553371786655273, 0.03603218685466068, 0.03610339671010468, 0.03895179092786442, 0.03902300078330841, 0.0391298155664744, 0.039201025421918397, 0.04108808659118422, 0.04115929644662821, 0.043010752688172046, 0.043081962543616036, 0.045396282845545824, 0.04546749270098982, 0.05013173823257139, 0.050202948088015384, 0.051164281136509296, 0.051235490991953285, 0.05137791070284127, 0.051449120558285266, 0.053015737378053124, 0.05308694723349711, 0.057110304066082744, 0.05718151392152674, 0.05789361247596667, 0.05796482233141067, 0.07971943316955067, 0.07971943316955067, 0.08395641956846828, 0.08395641956846828, 0.10838139998575803, 0.10838139998575803, 0.11026846115502385, 0.11026846115502385, 0.11069572028768782, 0.11076693014313181, 0.1118706829025137, 0.1119418927579577, 0.1120131026134017, 0.11208431246884569, 0.11350850957772556, 0.11357971943316955, 0.11361532436089154, 0.11368653421633554, 0.11400697856583351, 0.11407818842127751, 0.11439863277077547, 0.11446984262621947, 0.11450544755394147, 0.11457665740938545, 0.11461226233710746, 0.11468347219255146, 0.11475468204799544, 0.11482589190343943, 0.11507512639749341, 0.11514633625293741, 0.11649932350637328, 0.11657053336181727, 0.11746065655486719, 0.11753186641031119, 0.11895606351919105, 0.11909848323007904, 0.11977497685679699, 0.11984618671224097, 0.11995300149540697, 0.12002421135085095, 0.12162643309834081, 0.12169764295378481, 0.12194687744783878, 0.12201808730328277, 0.12337107455671865, 0.12344228441216264, 0.12347788933988464, 0.12354909919532864, 0.12486648152104252, 0.12493769137648651, 0.1250801110873745, 0.12515132094281847, 0.12529374065370646, 0.12536495050915047, 0.12568539485864844, 0.12582781456953643, 0.12636188848536636, 0.12643309834081037, 0.12664672790714235, 0.12671793776258633, 0.12782169052196823, 0.12789290037741224, 0.12810652994374422, 0.1281777397991882, 0.12892544328135014, 0.12899665313679412, 0.12949512212490208, 0.1295663319803461, 0.12967314676351208, 0.12974435661895606, 0.13013601082389803, 0.130207220679342, 0.130314035462508, 0.130314035462508, 0.130420850245674, 0.130492060101118, 0.13074129459517198, 0.13081250445061596, 0.1325571459089938, 0.1326995656198818, 0.1327707754753258, 0.1327707754753258, 0.13330484939115575, 0.13337605924659973, 0.1336252937406537, 0.1336965035960977, 0.13462223171686963, 0.1346934415723136, 0.13487146621092358, 0.1349782809940896, 0.13512070070497756, 0.13526312041586555, 0.13551235490991953, 0.13565477462080752, 0.1357259844762515, 0.13579719433169551, 0.13647368795841344, 0.13654489781385742, 0.13665171259702344, 0.13672292245246742, 0.13739941607918535, 0.13747062593462936, 0.13782667521184933, 0.1378978850672933, 0.1380046998504593, 0.1380759097059033, 0.13839635405540127, 0.13846756391084525, 0.13850316883856725, 0.13857437869401126, 0.13882361318806521, 0.13889482304350922, 0.13950010681478317, 0.13957131667022715, 0.14078188421277504, 0.14085309406821905, 0.14195684682760093, 0.14202805668304494, 0.1422060813216549, 0.14227729117709892, 0.1424197108879869, 0.1424909207434309, 0.14323862422559283, 0.1433098340810368, 0.14377269814142277, 0.14384390799686678, 0.1445916114790287, 0.1446628213344727, 0.14494766075624865, 0.14501887061169266, 0.14509008046713665, 0.14516129032258066, 0.14583778394929858, 0.14594459873246457, 0.14601580858790858, 0.14633625293740654, 0.14640746279285052, 0.1466923022146265, 0.1467635120700705, 0.14701274656412447, 0.14708395641956848, 0.14729758598590045, 0.14740440076906644, 0.14754682047995443, 0.1478672648294524, 0.14793847468489638, 0.14825891903439437, 0.14833012888983835, 0.14872178309478032, 0.1487929929502243, 0.14904222744427828, 0.14918464715516627, 0.14922025208288828, 0.14929146193833226, 0.14943388164922025, 0.14950509150466423, 0.14957630136010824, 0.14968311614327423, 0.1498967457096062, 0.14996795556505021, 0.1500747703482162, 0.15014598020366018, 0.15025279498682617, 0.15032400484227018, 0.15050202948088015, 0.15064444919176814, 0.15071565904721212, 0.15092928861354413, 0.1510004984689881, 0.15146336252937406, 0.15157017731254005, 0.15164138716798406, 0.15171259702342804, 0.15178380687887202, 0.15189062166203804, 0.15196183151748202, 0.15249590543331196, 0.15263832514419995, 0.15270953499964396, 0.15292316456597593, 0.15302997934914192, 0.1533148187709179, 0.1533860286263619, 0.15349284340952787, 0.15356405326497188, 0.15359965819269386, 0.15367086804813787, 0.15384889268674784, 0.15392010254219185, 0.15406252225307981, 0.15416933703624583, 0.15441857153029978, 0.1544897813857438, 0.15463220109663178, 0.15470341095207576, 0.15484583066296376, 0.15491704051840774, 0.15513067008473974, 0.15520187994018372, 0.1553086947233497, 0.1553799045787937, 0.1555935341451257, 0.15570034892829168, 0.15577155878373566, 0.15584276863917967, 0.15591397849462366, 0.15602079327778964, 0.15612760806095563, 0.15619881791639964, 0.15644805241045362, 0.1565192622658976, 0.15669728690450757, 0.15676849675995158, 0.15683970661539556, 0.15691091647083957, 0.15694652139856155, 0.15701773125400556, 0.15737378053122553, 0.1574449903866695, 0.1575874100975575, 0.15765861995300148, 0.1577298298084455, 0.15780103966388948, 0.15783664459161148, 0.15794345937477747, 0.15805027415794345, 0.15812148401338746, 0.15826390372427543, 0.15833511357971944, 0.15840632343516342, 0.15847753329060743, 0.1586199530014954, 0.1586911628569394, 0.15897600227871536, 0.15904721213415937, 0.15918963184504736, 0.15926084170049135, 0.15933205155593533, 0.15965249590543332, 0.1597237057608773, 0.15993733532720927, 0.16000854518265328, 0.1607918535925372, 0.1608630634479812, 0.1609342733034252, 0.1609342733034252, 0.16132592750836716, 0.16139713736381114, 0.16161076693014312, 0.16171758171330913, 0.1617531866410311, 0.16182439649647512, 0.1618600014241971, 0.1619312112796411, 0.16214484084597308, 0.16221605070141706, 0.16225165562913907, 0.16232286548458308, 0.163034964039023, 0.163106173894467, 0.16349782809940896, 0.16356903795485295, 0.16374706259346294, 0.16381827244890693, 0.16385387737662893, 0.1639250872320729, 0.16428113650929288, 0.1643523463647369, 0.16445916114790288, 0.16453037100334686, 0.16467279071423485, 0.16474400056967883, 0.16485081535284482, 0.16495763013601084, 0.16545609912411877, 0.16552730897956278, 0.16559851883500676, 0.16574093854589475, 0.16577654347361676, 0.16588335825678274, 0.1661681976785587, 0.1662394075340027, 0.16670227159438866, 0.16677348144983264, 0.16709392579933063, 0.16716513565477462, 0.16720074058249662, 0.1673075553656626, 0.1675567898597166, 0.16762799971516057, 0.16777041942604856, 0.16784162928149257, 0.16794844406465856, 0.16801965392010254, 0.16812646870326853, 0.1683400982696005, 0.1684113081250445, 0.1685181229082105, 0.16858933276365448, 0.16883856725770846, 0.16890977711315247, 0.16901659189631846, 0.16908780175176244, 0.16912340667948444, 0.16919461653492843, 0.1697286904507584, 0.16979990030620237, 0.16983550523392438, 0.16994232001709036, 0.16997792494481237, 0.17004913480025635, 0.17047639393292033, 0.17058320871608632, 0.1706544185715303, 0.17076123335469628, 0.17101046784875026, 0.17115288755963826, 0.17129530727052625, 0.17136651712597023, 0.17232785017446414, 0.17239906002990815, 0.17243466495763013, 0.17250587481307414, 0.17336039307840206, 0.17343160293384605, 0.17385886206651, 0.17396567684967598, 0.17435733105461795, 0.17442854091006196, 0.17489140497044792, 0.1749626148258919, 0.17531866410311187, 0.17538987395855588, 0.17571031830805384, 0.17578152816349782, 0.1758883429466638, 0.17677846613971374, 0.17684967599515772, 0.17692088585060173, 0.17702770063376772, 0.17738374991098768, 0.17752616962187567, 0.17756177454959765, 0.17763298440504166, 0.17880794701986755, 0.17887915687531156, 0.17948444064658547, 0.17955565050202948, 0.17994730470697146, 0.18008972441785942, 0.1805525884782454, 0.18062379833368938, 0.18073061311685537, 0.18080182297229935, 0.18097984761090935, 0.18105105746635333, 0.1813002919604073, 0.18137150181585132, 0.18190557573168126, 0.18197678558712527, 0.1823684397920672, 0.18243964964751122, 0.1825108595029552, 0.1826532792138432, 0.18297372356334116, 0.18304493341878517, 0.18311614327422915, 0.18318735312967316, 0.18393505661183507, 0.18404187139500106, 0.18461155023855302, 0.184682760093997, 0.18511001922666098, 0.18518122908210496, 0.18571530299793493, 0.1857865128533789, 0.1858933276365449, 0.18596453749198888, 0.18642740155237486, 0.18649861140781884, 0.18867051199886065, 0.18874172185430463, 0.18891974649291463, 0.1889909563483586, 0.1900947091077405, 0.1901659189631845, 0.1902015238909065, 0.1902727337463505, 0.19212418998789432, 0.1922310047710603, 0.19287189347005626, 0.19294310332550024, 0.1934771772413302, 0.1935483870967742, 0.19750053407391582, 0.1976073488570818, 0.1988179163996297, 0.1988891262550737, 0.20195115003916542, 0.20202235989460943, 0.5359253720714947, 0.5359253720714947, 0.8402762942391226, 0.8402762942391226, 0.8840703553371787, 0.8840703553371787, 0.9212775048066653, 0.9213487146621092, 0.9214555294452752, 0.9215267393007193, 0.9218827885779391, 0.9219539984333832, 0.923734244819483, 0.923805454674927, 0.923912269458093, 0.923983479313537, 0.924268318735313, 0.924375133518479, 0.9261909848323008, 0.9262621946877447, 0.9265114291817987, 0.9265826390372428, 0.9271879228085167, 0.9272947375916827, 0.9295378480381685, 0.9296446628213345, 0.9322438225450402, 0.9323150324004842, 0.9327066866054262, 0.9327778964608702, 0.9336680196539201, 0.933739229509364, 0.9339172541479741, 0.9339884640034181, 0.935127821690522, 0.935234636473688, 0.93580431531724, 0.9358755251726839, 0.9362315744499039, 0.9363383892330699, 0.9368012532934558, 0.9369436730043438, 0.9371216976429538, 0.9372285124261198, 0.9376557715587838, 0.9377269814142277, 0.9380474257637257, 0.9381186356191696, 0.9399700918607136, 0.9400413017161575, 0.9401837214270455, 0.9402549312824895, 0.9409314249092074, 0.9410026347646514, 0.9434949797051913, 0.9435661895606352, 0.945382040874457, 0.945488855657623, 0.9471266823328348, 0.9471978921882789, 0.9473759168268888, 0.9474471266823329, 0.9478387808872748, 0.9479099907427188, 0.9491561632129887, 0.9492273730684326, 0.9502955209000926, 0.9503667307555366, 0.9504735455387026, 0.9505447553941465, 0.9507227800327566, 0.9507939898882005, 0.9512924588763085, 0.9513636687317525, 0.9514704835149185, 0.9515416933703624, 0.9518265327921385, 0.9518977426475824, 0.9521469771416364, 0.9522181869970804, 0.9522893968525243, 0.9523606067079684, 0.9528234707683544, 0.9528946806237983, 0.9529658904792423, 0.9530371003346864, 0.9533931496119062, 0.9534643594673503, 0.9536423841059603, 0.9537135939614042, 0.9540340383109023, 0.9541052481663462, 0.9543900875881222, 0.9544612974435662, 0.9545681122267322, 0.9546393220821762, 0.9548885565762302, 0.9549597664316741, 0.9553870255643381, 0.9555294452752261, 0.9557430748415581, 0.955814284697002, 0.95595670440789, 0.956027914263334, 0.956063519191056, 0.9561347290465, 0.956170333974222, 0.956277148757388, 0.956383963540554, 0.95649077832372, 0.956597593106886, 0.95666880296233, 0.956775617745496, 0.956882432528662, 0.9571316670227159, 0.9572384818058819, 0.957309691661326, 0.9575945310831019, 0.9577013458662679, 0.9580573951434879, 0.9581998148543759, 0.9582710247098198, 0.9584134444207079, 0.9585558641315958, 0.9586982838424838, 0.9587338887702058, 0.9588763084810937, 0.9591611479028698, 0.9592323577583137, 0.9594459873246457, 0.9595171971800898, 0.9596240119632558, 0.9604429253008616, 0.9605141351563057, 0.9609413942889696, 0.9610482090721356, 0.9612618386384676, 0.9614042583493555, 0.9616178879156876, 0.9616890977711315, 0.9620095421206295, 0.9620095421206295, 0.9621163569037955, 0.9621875667592394, 0.9623299864701275, 0.9624011963255714, 0.9626148258919034, 0.9627216406750694, 0.9628996653136794, 0.9629708751691234, 0.9631132948800114, 0.9632557145908994, 0.9633269244463434, 0.9635761589403974, 0.9636473687958413, 0.9637185786512853, 0.9637897885067294, 0.9640034180730613, 0.9640746279285053, 0.9643594673502813, 0.9644306772057253, 0.9644662821334473, 0.9645374919888913, 0.9645730969166133, 0.9646443067720573, 0.9651427757601652, 0.9652139856156092, 0.9656412447482732, 0.9657124546037171, 0.9658548743146051, 0.9659260841700491, 0.9663177383749911, 0.9663889482304351, 0.966460158085879, 0.9665313679413231, 0.9667449975076551, 0.9668518122908211, 0.966923022146265, 0.9669942320017091, 0.967065441857153, 0.967136651712597, 0.967350281278929, 0.967421491134373, 0.967635120700705, 0.967706330556149, 0.967813145339315, 0.9680267749056469, 0.9680979847610909, 0.9681335896888129, 0.9682404044719789, 0.9684540340383109, 0.9685608488214769, 0.9685964537491989, 0.9686676636046428, 0.9687744783878088, 0.9688100833155309, 0.9688812931709748, 0.9689525030264189, 0.9690237128818628, 0.9690593178095849, 0.9691661325927509, 0.9692729473759168, 0.9693441572313608, 0.9694153670868049, 0.9694865769422488, 0.9695221818699709, 0.9696646015808588, 0.9697714163640248, 0.9698426262194688, 0.9700562557858008, 0.9701274656412447, 0.9704123050630207, 0.9704835149184647, 0.9710887986897386, 0.9711600085451827, 0.9712668233283487, 0.9713380331837926, 0.9720501317382326, 0.9721213415936766, 0.9722637613045646, 0.9723349711600086, 0.9724061810154525, 0.9726910204372285, 0.9729758598590045, 0.9736167485580004, 0.9737235633411664, 0.9739015879797764, 0.9740084027629424, 0.9740796126183864, 0.9976500747703482, 0.9977212846257922, 0.9980061240475682, 0.9981485437584562, 0.9982909634693442, 0.9983621733247882, 0.9995015310118921, 0.9996083457950581, 1.0], \"y\": [0.04, 0.04, 0.08, 0.08, 0.12, 0.12, 0.16, 0.16, 0.2, 0.2, 0.24, 0.24, 0.28, 0.28, 0.32, 0.32, 0.36, 0.36, 0.4, 0.4, 0.44, 0.44, 0.48, 0.48, 0.52, 0.52, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.6, 0.6, 0.64, 0.64, 0.68, 0.68, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.88, 0.88, 0.92, 0.92, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 0.96, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \"type\": \"scatter\", \"uid\": \"42e7ced3-70e1-4cc4-af15-4904d9293406\"}, {\"mode\": \"lines\", \"name\": \"Baseline Area: 50.0\", \"x\": [0, 1], \"y\": [0, 1], \"type\": \"scatter\", \"uid\": \"aa64faeb-39bc-4174-a9a9-3984dafbe6fa\"}], {\"height\": 600, \"title\": {\"text\": \"Receiver Operating Characteristic - Area Under Curve\"}, \"width\": 650}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC-AUC figure\n",
    "\n",
    "data = [\n",
    "    {\n",
    "      'x':FPR, \n",
    "      'y':TPR, \n",
    "      'type':'scatter',\n",
    "      'mode': 'lines',\n",
    "      'name': 'AUC: '+str(roc_score)\n",
    "      },\n",
    "     {'x':[0,1], \n",
    "      'y':[0,1], \n",
    "      'type':'scatter',\n",
    "      'mode': 'lines',\n",
    "      'name': 'Baseline Area: 50.0'}]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Receiver Operating Characteristic - Area Under Curve',\n",
    "    width=650,\n",
    "    height=600, \n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A confusion matrix tells us our false positives and false negatives:\n",
    "matrix=confusion_matrix(y_test, predictions)\n",
    "cm=pd.DataFrame(matrix, columns=['predicted: +', 'predicted: -'], index=['ground truth: +', 'ground truth: -'])\n",
    "cm=cm.reset_index(drop=False)\n",
    "cm=cm.rename(columns={'index': f'n = {len(y_test)}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "#00083e"
          ],
          [
           0.5,
           "#ededee"
          ],
          [
           1,
           "#ffffff"
          ]
         ],
         "hoverinfo": "none",
         "opacity": 0.75,
         "showscale": false,
         "type": "heatmap",
         "uid": "f8a19362-eadd-483b-ab5d-52b283ca3d76",
         "z": [
          [
           0,
           0,
           0
          ],
          [
           0.5,
           0.5,
           0.5
          ],
          [
           1,
           1,
           1
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "align": "left",
          "font": {
           "color": "#ffffff"
          },
          "showarrow": false,
          "text": "<b>n = 28111</b>",
          "x": -0.45,
          "xanchor": "left",
          "xref": "x",
          "y": 0,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#ffffff"
          },
          "showarrow": false,
          "text": "<b>predicted: +</b>",
          "x": 0.55,
          "xanchor": "left",
          "xref": "x",
          "y": 0,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#ffffff"
          },
          "showarrow": false,
          "text": "<b>predicted: -</b>",
          "x": 1.55,
          "xanchor": "left",
          "xref": "x",
          "y": 0,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "ground truth: +",
          "x": -0.45,
          "xanchor": "left",
          "xref": "x",
          "y": 1,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "25007",
          "x": 0.55,
          "xanchor": "left",
          "xref": "x",
          "y": 1,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "3079",
          "x": 1.55,
          "xanchor": "left",
          "xref": "x",
          "y": 1,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "ground truth: -",
          "x": -0.45,
          "xanchor": "left",
          "xref": "x",
          "y": 2,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "8",
          "x": 0.55,
          "xanchor": "left",
          "xref": "x",
          "y": 2,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "17",
          "x": 1.55,
          "xanchor": "left",
          "xref": "x",
          "y": 2,
          "yref": "y"
         }
        ],
        "height": 140,
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "xaxis": {
         "dtick": 1,
         "gridwidth": 2,
         "showticklabels": false,
         "tick0": -0.5,
         "ticks": "",
         "zeroline": false
        },
        "yaxis": {
         "autorange": "reversed",
         "dtick": 1,
         "gridwidth": 2,
         "showticklabels": false,
         "tick0": 0.5,
         "ticks": "",
         "zeroline": false
        }
       }
      },
      "text/html": [
       "<div id=\"22466cf5-e36b-4692-9ee2-361186b071a9\" style=\"height: 140px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"22466cf5-e36b-4692-9ee2-361186b071a9\")) {\n",
       "    Plotly.newPlot(\"22466cf5-e36b-4692-9ee2-361186b071a9\", [{\"colorscale\": [[0, \"#00083e\"], [0.5, \"#ededee\"], [1, \"#ffffff\"]], \"hoverinfo\": \"none\", \"opacity\": 0.75, \"showscale\": false, \"z\": [[0, 0, 0], [0.5, 0.5, 0.5], [1, 1, 1]], \"type\": \"heatmap\", \"uid\": \"f8a19362-eadd-483b-ab5d-52b283ca3d76\"}], {\"annotations\": [{\"align\": \"left\", \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false, \"text\": \"<b>n = 28111</b>\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false, \"text\": \"<b>predicted: +</b>\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false, \"text\": \"<b>predicted: -</b>\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"ground truth: +\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 1, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"25007\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 1, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"3079\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 1, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"ground truth: -\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"8\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"17\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}], \"height\": 140, \"margin\": {\"b\": 0, \"l\": 0, \"r\": 0, \"t\": 0}, \"xaxis\": {\"dtick\": 1, \"gridwidth\": 2, \"showticklabels\": false, \"tick0\": -0.5, \"ticks\": \"\", \"zeroline\": false}, \"yaxis\": {\"autorange\": \"reversed\", \"dtick\": 1, \"gridwidth\": 2, \"showticklabels\": false, \"tick0\": 0.5, \"ticks\": \"\", \"zeroline\": false}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"22466cf5-e36b-4692-9ee2-361186b071a9\")) {window._Plotly.Plots.resize(document.getElementById(\"22466cf5-e36b-4692-9ee2-361186b071a9\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"22466cf5-e36b-4692-9ee2-361186b071a9\" style=\"height: 140px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"22466cf5-e36b-4692-9ee2-361186b071a9\")) {\n",
       "    Plotly.newPlot(\"22466cf5-e36b-4692-9ee2-361186b071a9\", [{\"colorscale\": [[0, \"#00083e\"], [0.5, \"#ededee\"], [1, \"#ffffff\"]], \"hoverinfo\": \"none\", \"opacity\": 0.75, \"showscale\": false, \"z\": [[0, 0, 0], [0.5, 0.5, 0.5], [1, 1, 1]], \"type\": \"heatmap\", \"uid\": \"f8a19362-eadd-483b-ab5d-52b283ca3d76\"}], {\"annotations\": [{\"align\": \"left\", \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false, \"text\": \"<b>n = 28111</b>\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false, \"text\": \"<b>predicted: +</b>\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false, \"text\": \"<b>predicted: -</b>\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"ground truth: +\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 1, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"25007\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 1, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"3079\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 1, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"ground truth: -\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"8\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"17\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}], \"height\": 140, \"margin\": {\"b\": 0, \"l\": 0, \"r\": 0, \"t\": 0}, \"xaxis\": {\"dtick\": 1, \"gridwidth\": 2, \"showticklabels\": false, \"tick0\": -0.5, \"ticks\": \"\", \"zeroline\": false}, \"yaxis\": {\"autorange\": \"reversed\", \"dtick\": 1, \"gridwidth\": 2, \"showticklabels\": false, \"tick0\": 0.5, \"ticks\": \"\", \"zeroline\": false}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"22466cf5-e36b-4692-9ee2-361186b071a9\")) {window._Plotly.Plots.resize(document.getElementById(\"22466cf5-e36b-4692-9ee2-361186b071a9\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.figure_factory as ff\n",
    "table = ff.create_table(cm)\n",
    "iplot(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature important (logistic reg coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "results=pd.DataFrame(list(zip(X_test.columns, logreg.coef_[0])), columns=['feature', 'coefficient'])\n",
    "results=results.sort_values(by='coefficient', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_coeffs=results.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attribute4</td>\n",
       "      <td>0.535093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>attribute4_lag01</td>\n",
       "      <td>0.469254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>attribute2_lag01</td>\n",
       "      <td>0.417921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attribute2</td>\n",
       "      <td>0.417046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>attribute4_lag02</td>\n",
       "      <td>0.406024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>attribute2_lag02</td>\n",
       "      <td>0.367693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>attribute4_lag03</td>\n",
       "      <td>0.364203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>attribute7_lag01</td>\n",
       "      <td>0.353935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>attribute7</td>\n",
       "      <td>0.352449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>attribute2_lag03</td>\n",
       "      <td>0.327986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>attribute2_lag04</td>\n",
       "      <td>0.316946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>attribute4_lag04</td>\n",
       "      <td>0.304469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>attribute7_lag03</td>\n",
       "      <td>0.292580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>attribute7_lag02</td>\n",
       "      <td>0.276835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>attribute7_lag04</td>\n",
       "      <td>0.255710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  coefficient\n",
       "3         attribute4     0.535093\n",
       "21  attribute4_lag01     0.469254\n",
       "13  attribute2_lag01     0.417921\n",
       "1         attribute2     0.417046\n",
       "22  attribute4_lag02     0.406024\n",
       "14  attribute2_lag02     0.367693\n",
       "23  attribute4_lag03     0.364203\n",
       "33  attribute7_lag01     0.353935\n",
       "6         attribute7     0.352449\n",
       "15  attribute2_lag03     0.327986\n",
       "16  attribute2_lag04     0.316946\n",
       "24  attribute4_lag04     0.304469\n",
       "35  attribute7_lag03     0.292580\n",
       "34  attribute7_lag02     0.276835\n",
       "36  attribute7_lag04     0.255710"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": [
           "#fde725",
           "#d8e219",
           "#addc30",
           "#84d44b",
           "#5ec962",
           "#3fbc73",
           "#28ae80",
           "#1fa088",
           "#21918c",
           "#26828e",
           "#2c728e",
           "#33638d",
           "#3b528b",
           "#424086",
           "#472d7b",
           "#48186a",
           "#440154"
          ]
         },
         "type": "bar",
         "uid": "903484ca-3047-41e3-8b7b-0f835e780d23",
         "x": [
          "attribute4",
          "attribute4_lag01",
          "attribute2_lag01",
          "attribute2",
          "attribute4_lag02",
          "attribute2_lag02",
          "attribute4_lag03",
          "attribute7_lag01",
          "attribute7",
          "attribute2_lag03",
          "attribute2_lag04",
          "attribute4_lag04",
          "attribute7_lag03",
          "attribute7_lag02",
          "attribute7_lag04"
         ],
         "y": [
          0.5350934960201712,
          0.46925431585376803,
          0.41792054739632484,
          0.4170460868760466,
          0.4060243375752158,
          0.3676933294974366,
          0.36420276930316614,
          0.35393474842525274,
          0.3524494405221047,
          0.3279858734687821,
          0.31694558329905065,
          0.3044689630216918,
          0.2925797205665989,
          0.276835143180643,
          0.25571001136005544
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Logistic Regression Results"
        },
        "xaxis": {
         "title": {
          "text": "Coefficients"
         }
        },
        "yaxis": {
         "title": {
          "text": "Odds Ratio to Failure"
         }
        }
       }
      },
      "text/html": [
       "<div id=\"ac090039-5b10-4b2a-b6d8-12d7c43d14b0\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"ac090039-5b10-4b2a-b6d8-12d7c43d14b0\")) {\n",
       "    Plotly.newPlot(\"ac090039-5b10-4b2a-b6d8-12d7c43d14b0\", [{\"marker\": {\"color\": [\"#fde725\", \"#d8e219\", \"#addc30\", \"#84d44b\", \"#5ec962\", \"#3fbc73\", \"#28ae80\", \"#1fa088\", \"#21918c\", \"#26828e\", \"#2c728e\", \"#33638d\", \"#3b528b\", \"#424086\", \"#472d7b\", \"#48186a\", \"#440154\"]}, \"x\": [\"attribute4\", \"attribute4_lag01\", \"attribute2_lag01\", \"attribute2\", \"attribute4_lag02\", \"attribute2_lag02\", \"attribute4_lag03\", \"attribute7_lag01\", \"attribute7\", \"attribute2_lag03\", \"attribute2_lag04\", \"attribute4_lag04\", \"attribute7_lag03\", \"attribute7_lag02\", \"attribute7_lag04\"], \"y\": [0.5350934960201712, 0.46925431585376803, 0.41792054739632484, 0.4170460868760466, 0.4060243375752158, 0.3676933294974366, 0.36420276930316614, 0.35393474842525274, 0.3524494405221047, 0.3279858734687821, 0.31694558329905065, 0.3044689630216918, 0.2925797205665989, 0.276835143180643, 0.25571001136005544], \"type\": \"bar\", \"uid\": \"903484ca-3047-41e3-8b7b-0f835e780d23\"}], {\"title\": {\"text\": \"Logistic Regression Results\"}, \"xaxis\": {\"title\": {\"text\": \"Coefficients\"}}, \"yaxis\": {\"title\": {\"text\": \"Odds Ratio to Failure\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"ac090039-5b10-4b2a-b6d8-12d7c43d14b0\")) {window._Plotly.Plots.resize(document.getElementById(\"ac090039-5b10-4b2a-b6d8-12d7c43d14b0\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"ac090039-5b10-4b2a-b6d8-12d7c43d14b0\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"ac090039-5b10-4b2a-b6d8-12d7c43d14b0\")) {\n",
       "    Plotly.newPlot(\"ac090039-5b10-4b2a-b6d8-12d7c43d14b0\", [{\"marker\": {\"color\": [\"#fde725\", \"#d8e219\", \"#addc30\", \"#84d44b\", \"#5ec962\", \"#3fbc73\", \"#28ae80\", \"#1fa088\", \"#21918c\", \"#26828e\", \"#2c728e\", \"#33638d\", \"#3b528b\", \"#424086\", \"#472d7b\", \"#48186a\", \"#440154\"]}, \"x\": [\"attribute4\", \"attribute4_lag01\", \"attribute2_lag01\", \"attribute2\", \"attribute4_lag02\", \"attribute2_lag02\", \"attribute4_lag03\", \"attribute7_lag01\", \"attribute7\", \"attribute2_lag03\", \"attribute2_lag04\", \"attribute4_lag04\", \"attribute7_lag03\", \"attribute7_lag02\", \"attribute7_lag04\"], \"y\": [0.5350934960201712, 0.46925431585376803, 0.41792054739632484, 0.4170460868760466, 0.4060243375752158, 0.3676933294974366, 0.36420276930316614, 0.35393474842525274, 0.3524494405221047, 0.3279858734687821, 0.31694558329905065, 0.3044689630216918, 0.2925797205665989, 0.276835143180643, 0.25571001136005544], \"type\": \"bar\", \"uid\": \"903484ca-3047-41e3-8b7b-0f835e780d23\"}], {\"title\": {\"text\": \"Logistic Regression Results\"}, \"xaxis\": {\"title\": {\"text\": \"Coefficients\"}}, \"yaxis\": {\"title\": {\"text\": \"Odds Ratio to Failure\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"ac090039-5b10-4b2a-b6d8-12d7c43d14b0\")) {window._Plotly.Plots.resize(document.getElementById(\"ac090039-5b10-4b2a-b6d8-12d7c43d14b0\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's display that with Plotly.\n",
    "mydata = [go.Bar(\n",
    "    x=big_coeffs['feature'],\n",
    "    y=big_coeffs['coefficient'],\n",
    "    marker=dict(color=Viridis[::-1])\n",
    ")]\n",
    "\n",
    "mylayout = go.Layout(\n",
    "    title='Logistic Regression Results',\n",
    "    xaxis = dict(title = 'Coefficients'), \n",
    "    yaxis = dict(title = 'Odds Ratio to Failure'), \n",
    "\n",
    ")\n",
    "fig = go.Figure(data=mydata, layout=mylayout)\n",
    "pio.write_image(fig, '../images/logistic.png')\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Were these features highly correlated with the outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attribute4',\n",
       " 'attribute4_lag01',\n",
       " 'attribute2_lag01',\n",
       " 'attribute2',\n",
       " 'attribute4_lag02',\n",
       " 'failure']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=list(big_coeffs.feature)[:5]\n",
    "cols.append('failure')\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute4</th>\n",
       "      <th>attribute4_lag01</th>\n",
       "      <th>attribute2_lag01</th>\n",
       "      <th>attribute2</th>\n",
       "      <th>attribute4_lag02</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>attribute4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991320</td>\n",
       "      <td>0.209833</td>\n",
       "      <td>0.213120</td>\n",
       "      <td>0.983055</td>\n",
       "      <td>0.064157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attribute4_lag01</th>\n",
       "      <td>0.991320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.210570</td>\n",
       "      <td>0.210180</td>\n",
       "      <td>0.991663</td>\n",
       "      <td>0.056897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attribute2_lag01</th>\n",
       "      <td>0.209833</td>\n",
       "      <td>0.210570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991008</td>\n",
       "      <td>0.207976</td>\n",
       "      <td>0.058904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attribute2</th>\n",
       "      <td>0.213120</td>\n",
       "      <td>0.210180</td>\n",
       "      <td>0.991008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206883</td>\n",
       "      <td>0.059865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attribute4_lag02</th>\n",
       "      <td>0.983055</td>\n",
       "      <td>0.991663</td>\n",
       "      <td>0.207976</td>\n",
       "      <td>0.206883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failure</th>\n",
       "      <td>0.064157</td>\n",
       "      <td>0.056897</td>\n",
       "      <td>0.058904</td>\n",
       "      <td>0.059865</td>\n",
       "      <td>0.052150</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  attribute4  attribute4_lag01  attribute2_lag01  attribute2  \\\n",
       "attribute4          1.000000          0.991320          0.209833    0.213120   \n",
       "attribute4_lag01    0.991320          1.000000          0.210570    0.210180   \n",
       "attribute2_lag01    0.209833          0.210570          1.000000    0.991008   \n",
       "attribute2          0.213120          0.210180          0.991008    1.000000   \n",
       "attribute4_lag02    0.983055          0.991663          0.207976    0.206883   \n",
       "failure             0.064157          0.056897          0.058904    0.059865   \n",
       "\n",
       "                  attribute4_lag02   failure  \n",
       "attribute4                0.983055  0.064157  \n",
       "attribute4_lag01          0.991663  0.056897  \n",
       "attribute2_lag01          0.207976  0.058904  \n",
       "attribute2                0.206883  0.059865  \n",
       "attribute4_lag02          1.000000  0.052150  \n",
       "failure                   0.052150  1.000000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cols].corr()\n",
    "# No, they were not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How often are we accurate when aggregated to the device level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test:  28111\n",
      "probabilities:  28111\n",
      "combined:  28111\n"
     ]
    }
   ],
   "source": [
    "y1_test=y1_test.reset_index(drop=True) # for the concat to work correctly, must have a clean index.\n",
    "preds_df=pd.DataFrame(predictions, columns=['preds'])\n",
    "combined_testdf=pd.concat([y1_test, preds_df], axis=1)\n",
    "\n",
    "print('y_test: ', len(y1_test))\n",
    "print('probabilities: ', len(preds_df))\n",
    "print('combined: ', len(combined_testdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>failure</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1F0S68M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z1F1R76A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W1F16RA7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1F131F6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W1F14GTK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     device  failure  preds\n",
       "0  S1F0S68M        0      0\n",
       "1  Z1F1R76A        0      0\n",
       "2  W1F16RA7        0      0\n",
       "3  S1F131F6        0      0\n",
       "4  W1F14GTK        0      0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(676, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>failure</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1F01E6Y</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1F01XDJ</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1F023H2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1F02L38</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1F03YZM</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     device   failure     preds\n",
       "0  S1F01E6Y  0.000000  0.000000\n",
       "1  S1F01XDJ  0.000000  0.000000\n",
       "2  S1F023H2  0.166667  0.833333\n",
       "3  S1F02L38  0.000000  0.000000\n",
       "4  S1F03YZM  0.012821  0.461538"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggdf=combined_testdf.groupby('device')[['device', 'failure', 'preds']].mean().reset_index(drop=False)\n",
    "print(aggdf.shape)\n",
    "aggdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    651\n",
       "1     25\n",
       "Name: failed, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggdf['failed']=0\n",
    "aggdf.loc[aggdf['failure']>0, 'failed']=1\n",
    "aggdf['failed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    536\n",
       "1    140\n",
       "Name: pred_failed, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggdf['pred_failed']=0\n",
    "aggdf.loc[aggdf['preds']>0, 'pred_failed']=1\n",
    "aggdf['pred_failed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred_failed</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>528</td>\n",
       "      <td>123</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>536</td>\n",
       "      <td>140</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred_failed    0    1  All\n",
       "failed                    \n",
       "0            528  123  651\n",
       "1              8   17   25\n",
       "All          536  140  676"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix (device level)\n",
    "pd.crosstab(aggdf['failed'], aggdf['pred_failed'],  margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification model does a poor job of identifying true negatives. It only identifies 13% of failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
